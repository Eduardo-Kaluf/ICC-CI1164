\documentclass[11pt]{article}

\title{Otimização de Desempenho para Sistemas Lineares Esparsos com Pré-condicionantes}
\author{SERGIO SIVONEI DE SANT'ANA FILHO GRR20242337\\EDUARDO KALUF GRR20241770}
\date{\today}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage{url}
\usepackage{hyperref}
\usepackage{graphicx}


% compile -> latexmk -pdf relatorio.tex
% clean   -> latexmk -C

\begin{document}
    \maketitle

    \section{Introdução}\label{sec:introducao}

    Este trabalho visa principalmente realizar a otimização de operações computacionais chave dentro do algoritmo do Método dos Gradientes Conjugados (CG),
    visando calcular de forma mais eficiente a solução de sistemas lineares da forma $Ax=b$.

    Especificamente, busca-se aprimorar e avaliar o desempenho do programa computacional desenvolvido no 1º Trabalho Prático.

    As operações críticas que foram alvo de otimização são:
    \begin{itemize}
        \item A Iteração Central do Método de Gradiente Conjugado utilizando o Pré-condicionador de Jacobi (PCG).
        \item O Cálculo do Resíduo do sistema.
    \end{itemize}

    A motivação para estas otimizações reside na natureza intensiva em computação dessas operações, bem como no grande tráfego de memória, especialmente ao lidar com matrizes esparsas de grande dimensão.

    \section{Otimizações Implementadas}\label{sec:otimizacoes}

    Nesta seção, detalhamos as técnicas de otimização aplicadas às operações, descrevendo seu impacto teórico e prático no desempenho,
    bem como os desafios encontrados durante o processo de implementação e ajuste.

    \subsection{Otimização do Gradiente Conjugado (PCG)}\label{subsec:gradiente}

    A otimização da iteração do Gradiente Conjugado, que envolve múltiplas operações de produto matriz-vetor ($A \times v$),
    foi realizada primariamente através da alteração do formato de armazenamento da matriz do sistema.

    \subsubsection{Matriz CSR (Compressed Sparse Row)}\label{subsubsec:csr}

    O formato \textbf{CSR} (Compressed Sparse Row) foi a principal modificação estrutural implementada.

    Este foi o terceiro método de armazenar a matriz que experimentamos, primeiramente tentamos guardá-las em um único vetor sem offsets e
    depois tentamos em diversos vetores de tamanhos diferentes.
    Desistimos de ambas as implementações, pois não pareciam práticas para realizar as operações e não ofertavam nenhum grande benefício
    aparente além da diminuição do tanto de memório utilizada

    O método escolhido é um esquema de armazenamento de matrizes projetado especificamente para lidar com matrizes esparsas, ou seja,
    matrizes que possuem uma alta proporção de elementos nulos.

    Este formato elimina a necessidade de armazenar informações redundantes (os zeros), operando sobre apenas três vetores de dimensão reduzida:
    \begin{itemize}
        \item \textbf{'Values'}: armazena apenas os valores não nulos da matriz.
        \item \textbf{'Col\_indices'}: armazena os índices das colunas correspondentes a cada valor não nulo.
        \item \textbf{'Row\_pointers'}: armazena os índices que indicam o início de cada nova linha nos vetores \('\)values' e \('\)col\_indices'.
    \end{itemize}
    A principal vantagem do \textbf{CSR} é sua extrema eficiência para operações de multiplicação matriz-vetor ($A \times v$).

    Dada a estrutura da iteração do Gradiente Conjugado (PCG), que exige duas ou mais dessas multiplicações por passo, o uso do \textbf{CSR} é crucial para reduzir o tempo de execução.
    Esta abordagem melhora a localidade de dados e permite \textbf{acessos sequenciais} à memória, que são mais rápidos e otimizam a utilização da cache.

    \textbf{Vetorialização (Uso de AVX):} Além disso, devido ao modo como o armazenamento \textbf{CSR} funciona, foi possível utilizar \textbf{AVX} neste método, deixando
    a iteração do método ainda mais rápida.
    A vetorização utiliza as Extensões Avançadas de Vetor (\textbf{AVX}) do processador, permitindo que uma única instrução da CPU
    (SIMD - Single Instruction, Multiple Data) opere simultaneamente sobre múltiplos dados.
    Isso foi essencial para \textbf{diminuir drasticamente} o tempo de execução das operações vetoriais, explorando a capacidade de paralelismo ao nível de hardware.

    \subsection{Otimização do Cálculo do Resíduo}\label{subsec:residuo}

    O cálculo do resíduo $r = b - A x$ requer primariamente uma multiplicação matriz-vetor e uma subtração de vetores.
    A otimização focou em garantir a máxima eficiência nessas operações, complementando a desempenho obtida com a implementação do \textbf{CSR} para
    multiplicação entre matriz vetor.

    Foram feitas algumas pequenas alterações de otimização, porém o maior ganho de desempenho foi devido a estrutura \textbf{CSR}. Houve também a tentativa de implementar o \textit{loop unroll} \& \textit{jam}, 
    porém sem sucesso, pois os testes mostraram uma piora significativa no tempo de execução do calcúlo.

    Outra otimização foi realizar parte do calculo da norma dentro do laço que cálcula o vetor resíduo, assim aproveitando um valor que já 
    está em memória sem a necessidade de outro loop que iria acessar todas as posições novamente. Todavia, nos testes realizados, 
    não foi observado grande mudança, na maioria apenas pequenas variações de tempo.

    \subsection{Otimização Adicional: Matrizes Simétricas Positivas}\label{subsec:simetrica}

    Além das duas operações fundamentais também otimizamos como a matriz simétrica positiva é calculada.
    O método \textbf{CSR} é ruim quando se é necessário percorrer pelas colunas, sendo assim, a multiplicação de duas matrizes do jeito convencional
    ficaria mais lento que o esperado, a fim de contornar isso, fizemos a multiplicação entre a matriz principal e a transposta pelas linhas, ou seja, ao invés de multiplicar
    linhas por colunas, multiplicamos linhas por linhas.
    Além disso, o método apenas itera quando existe algum resultado possível, multiplicações que irão dar zero no final são ignorados pois não são necessárias.

    \section{Resultados e Análise de Desempenho}\label{sec:resultados}

    Os resultados demonstram que a combinação do armazenamento \textbf{CSR} com a vetorização \textbf{AVX} produziu uma redução significativa no tempo de execução total,
    especialmente em sistemas de alta dimensão e esparsidade.

    A Tabela 1 resume o ganho de desempenho (speedup) alcançado para as operações críticas:

    \begin{table}[h]
        \centering
        \caption{Comparação de Tempo de Execução: Original vs. Otimizado (Tempo para N = 20.000 em milisegundos)}
        \begin{tabular}{|c|c|c|c|}
            \hline
            \textbf{Operação} & \textbf{Tempo Original} & \textbf{Tempo Otimizado} & \textbf{Speedup} \\
            \hline
            Iteração do PCG & 23.60  & 0.0097 & 2432.98x \\
            \hline
            Cálculo do Resíduo & 0.87 & 0.17 & 5.11x \\
            \hline
        \end{tabular}\label{tab:table}
    \end{table}

    Vale ressaltar que no teste de N = 20.000 do 1º trabalho, o \textbf{LIKWID} não gerou nenhum dado correspondente a execução, portanto apenas a medida de tempo deve ser considerada, já que todas as outras 
    são iguais a zero. 

    \section{Estimativa de Desempenho}\label{sec:Estimativa de Desempenho}
    
    Baseado nas modificações implementadas na segunda versão e considerando uma máquina com 8GB de memória RAM disponível para seu programa e Sistemas com 7 (sete) diagonais, pode-se responder as perguntas 
    dadas no enunciado do trabalho.

    \begin{enumerate}
        \item Qual o valor máximo estimado da ordem N do sistema linear que você seria capaz de resolver?
        \vspace{1ex}

        \textit{Após breves discussões, concluímos que conseguiriamos resolver um sistema de ordem 12 aproximadamente, pois apesar de demanadar muito tempo e esforço, parece uma métrica realizável em algumas horas.}

        \item Qual o ganho estimado de tempo para uma iteração do método de Gradiente Conjugado com Pré-condicionador de Jacobi (em função de N)?

        \vspace{1ex}
        \textit{Estimamos que o ganho de desempenho seria algo dentre o intervalo de 8 a 16 vezes mais rápido, pois acreditavamos que isso já seria um ganho notável de desempenho.}

        \item Qual a estimativa para a quantidade de operações em ponto flutuante executadas em cada iteração do método de Gradiente Conjugado com Pré-condicionador de Jacobi (em função de N)?
        \vspace{1ex}

        \textit{Estimamos que teriamos em torno de 100 Flops Dp por segundo no método de Gradiente Conjulgado, coisa que já seria melhor que no primeiro trabalho.}

        \item Compare suas estimativas acima com os resultados obtidos nos testes.
       
        \vspace{1ex}
        \textit{Bom, apenas as perguntas '2.' e '3.' podem ser comparadas, visto que a primeira não trata sobre o programa/otimizações em si.}
        
        \textit{Sobre o ganho estimado (2.) percebemos que a diferença foi muito maior, chegando a casos da segunda versão apresentar um tempo de execução 2458 vezes menor que a versão 1.}
        
        \textit{Já sobre a quantidade de operações de ponto flutuante (3.), obtivemos 120 Flops Dp em media nos testes, bem como tivemos um expressivo aumento em Flops AVX.}
    \end{enumerate}



    \section{Conclusão}\label{sec:conclusao}

    Por fim, nota-se que as operações críticas do método dos Gradientes Conjugados foram otimizadas com sucesso.
    Utilizando métodos estruturais (como a matriz \textbf{CSR} para matrizes esparsas) e técnicas de paralelismo ao nível de instrução (como a \textbf{vetorização AVX}),
    alcançamos uma melhoria substancial no desempenho do programa.
    Conseguimos confirmar a execução otimizada pelo \textbf{AVX} em pelo menos uma das operações e, como resultado,
    \textbf{diminuímos drasticamente} o tempo de execução total do algoritmo, tornando o Método dos Gradientes Conjugados
    mais eficiente para a resolução de sistemas lineares de grande escala.

     \nocite{*}
     \bibliography{references}
     \bibliographystyle{plain}

\end{document}
