\documentclass[11pt]{article}

\title{Otimização de Desempenho para Sistemas Lineares Esparsos com Pré-condicionantes}
\author{SERGIO SIVONEI DE SANT'ANA FILHO GRR20242337\\EDUARDO KALUF GRR20241770}
\date{\today}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage{url}
\usepackage{hyperref}
\usepackage{graphicx}


% compile -> latexmk -pdf RELATORIO-ek24-sssaf24.tex
% clean   -> latexmk -C

\begin{document}
    \maketitle

    \section{Introdução}\label{sec:introducao}

    Este trabalho visa realizar principalmente a otimização de operações computacionais chave dentro do algoritmo do Método dos Gradientes Conjugados (CG),
    visando calcular de forma mais eficiente a solução de sistemas lineares da forma $Ax=b$.

    Especificamente, busca-se aprimorar e avaliar o desempenho do programa computacional desenvolvido no 1º Trabalho Prático.

    As operações críticas que foram alvo de otimização são:
    \begin{itemize}
        \item A Iteração Central do Método de Gradiente Conjugado utilizando o Pré-condicionador de Jacobi (PCG).
        \item O Cálculo do Resíduo do sistema.
    \end{itemize}

    A motivação para estas otimizações reside na natureza intensiva em computação dessas operações, bem como no grande tráfego de memória, especialmente ao lidar com matrizes esparsas de grande dimensão.

    \clearpage
    \section{Otimizações Implementadas}\label{sec:otimizacoes}

    Nesta seção, detalhamos as técnicas de otimização aplicadas às operações, descrevendo seu impacto teórico e prático no desempenho,
    bem como os desafios encontrados durante o processo de implementação e ajuste.

    \subsection{Otimização do Gradiente Conjugado (PCG)}\label{subsec:gradiente}

    A otimização da iteração do Gradiente Conjugado, que envolve múltiplas operações de produto matriz-vetor ($A \times v$),
    foi realizada primariamente através da alteração do formato de armazenamento da matriz do sistema.

    \subsubsection{Matriz CSR (Compressed Sparse Row)}\label{subsubsec:csr}

    O formato \textbf{CSR} (Compressed Sparse Row) foi a principal modificação estrutural implementada.

    Este foi o terceiro método de armazenar a matriz que experimentamos, primeiramente tentamos guardá-las em um único vetor sem offsets e
    depois tentamos em diversos vetores de tamanhos diferentes.
    Desistimos de ambas as implementações, pois não pareciam práticas para realizar as operações e não ofertavam nenhum grande benefício
    aparente além da diminuição do tanto de memório utilizada

    O método escolhido é um esquema de armazenamento de matrizes projetado especificamente para lidar com matrizes esparsas, ou seja,
    matrizes que possuem uma alta proporção de elementos nulos.

    Este formato elimina a necessidade de armazenar informações redundantes (os zeros), operando sobre apenas três vetores de dimensão reduzida:
    \begin{itemize}
        \item \textbf{'Values'}: armazena apenas os valores não nulos da matriz.
        \item \textbf{'Col\_indices'}: armazena os índices das colunas correspondentes a cada valor não nulo.
        \item \textbf{'Row\_pointers'}: armazena os índices que indicam o início de cada nova linha nos vetores \('\)values' e \('\)col\_indices'.
    \end{itemize}
    A principal vantagem do \textbf{CSR} é sua extrema eficiência para operações de multiplicação matriz-vetor ($A \times v$).

    Dada a estrutura da iteração do Gradiente Conjugado (PCG), que exige duas ou mais dessas multiplicações por passo, o uso do \textbf{CSR} é crucial para reduzir o tempo de execução.
    Esta abordagem melhora a localidade de dados e permite \textbf{acessos sequenciais} à memória, que são mais rápidos e otimizam a utilização da cache.

    \textbf{Vetorialização (Uso de AVX):} Além disso, devido ao modo como o armazenamento \textbf{CSR} funciona, foi possível utilizar \textbf{AVX} neste método, deixando
    a iteração do método ainda mais rápida.
    A vetorização utiliza as Extensões Avançadas de Vetor (\textbf{AVX}) do processador, permitindo que uma única instrução da CPU
    (SIMD - Single Instruction, Multiple Data) opere simultaneamente sobre múltiplos dados.
    Isso foi essencial para \textbf{diminuir drasticamente} o tempo de execução das operações vetoriais, explorando a capacidade de paralelismo ao nível de hardware.

    \subsection{Otimização do Cálculo do Resíduo}\label{subsec:residuo}

    O cálculo do resíduo $r = b - A x$ requer primariamente uma multiplicação matriz-vetor e uma subtração de vetores.
    A otimização focou em garantir a máxima eficiência nessas operações, complementando a desempenho obtida com a implementação do \textbf{CSR} para
    multiplicação entre matriz vetor.

    Foram feitas algumas pequenas alterações de otimização, porém o maior ganho de desempenho foi devido à estrutura \textbf{CSR}.
    Houve também a tentativa de implementar o \textit{loop unroll} \& \textit{jam},
    porém sem sucesso, pois os testes mostraram uma piora significativa no tempo de execução do calcúlo.

    Outra otimização foi realizar parte do cálculo da norma dentro do laço que cálcula o vetor resíduo, assim aproveitando um valor que já
    está em memória sem a necessidade de outro loop que iria acessar todas as posições novamente.
    Todavia, nos testes realizados, não foi observado grande mudança, na maioria apenas pequenas variações de tempo.

    \subsection{Otimização Adicional: Matrizes Simétricas Positivas}\label{subsec:simetrica}

    Além das duas operações fundamentais também otimizamos como a matriz simétrica positiva é calculada.
    O método \textbf{CSR} é ruim quando se é necessário percorrer pelas colunas, sendo assim, a multiplicação de duas matrizes do jeito convencional
    ficaria mais lento que o esperado, a fim de contornar isso, fizemos a multiplicação entre a matriz principal e a transposta pelas linhas, ou seja, ao invés de multiplicar
    linhas por colunas, multiplicamos linhas por linhas.
    Além disso, o método apenas itera quando existe algum resultado possível, multiplicações que irão dar zero no final são ignorados, pois não são necessárias.

    \section{Análise dos Gráficos}\label{sec:graphics}

    A seguir, seguem os gráficos com as métricas extraídas pelo programa \textbf{LIKWID}, conforme solicitado, para diversos valores de N\@.

    \subsection{Método dos Gradientes Conjugados (CG)}\label{subsec:cg)}

    \hspace*{-2.0cm}\includegraphics[width=16cm]{graphs/op1_gradient_Exec_Time}

    É possível observar a disparidade no tempo de execução entre o programa antigo e o novo.
    Torna-se evidente que os métodos de otimização utilizados obtiveram sucesso ao reduzir drasticamente o
    tempo de execução para a iteração do gradiente, especialmente para grandes valores de N,
    que é o foco principal do nosso interesse.

    Essa redução no tempo é justificada pela melhora nas métricas que analisaremos a seguir.

    \hspace*{-2.0cm}\includegraphics[width=16cm]{graphs/op1_gradient_Flops_Avx}
    
    Ao analisarmos os Flops \textbf{AVX} podemos concluir que houve um uso das Extensões Avançadas de Vetor (\textbf{AVX}) em maior escala,
    coisa que otimiza o programa ao fazer uso de instruções SIMD\@.

    A utilização do \textbf{AVX} foi possível pelo método como estamos armazenando a matriz, o \textbf{CSR} permite que diversas operações
    durante a multiplicação de matriz vetor sejam realizadas ao mesmo tempo, pois são realizadas em sequência, sem dependência de dados e
    sem nenhum desvio condicional.

    Pode-se inferir que os picos e vales que ocorrem nas potências de 2 no início do gráfico resultam de um mapeamento ineficiente da cache para alguns desses valores específicos.
    Esse fenômeno é comumente denominado \textbf{\textit{cache thrashing}}.

    \hspace*{-2.0cm}\includegraphics[width=16cm]{graphs/op1_gradient_Flops_Dp}
    
    Houve também um aumento no número de \textbf{FLOPs de precisão dupla (Double precision)} por segundo, o que impacta diretamente na velocidade do programa.
    Uma vez que um maior volume de operações ocorre no mesmo intervalo de tempo, isso significa que a máquina concluirá os cálculos mais rapidamente em comparação com a versão anterior.

    É importante ressaltar que a taxa de FLOPs por segundo é inversamente proporcional ao tempo de execução do programa.
    Ou seja, o aumento dessa métrica ocorreu tanto por uma diminuição no tempo total necessário para realizar as operações quanto por uma diminuição no total de operações realizadas.

    Esta métrica apresenta os mesmos picos e vales que o gráfico anterior, pois o mesmo problema ocorre.

    \hspace*{-2.0cm}\includegraphics[width=16cm]{graphs/op1_gradient_L2Cache}

    Analisando o gráfico de miss ratio da cache L2 é possível inferir que: para sistemas de tamanhos condizentes com a Cache L2 (256-512) temos um desempenho expressivo da versão otimizada.
    Todavia, quando o tamanho aumenta muito temos uma piora por não ser mais possível aproveitar a localidade na cache, o que chega deixar o miss ratio da versão otimizada levemente pior que da versão original.

    Além disso, pode-se afirmar que a primeira versão do trabalho tem um desempenho mais consistente, apesar de ruim.
    Coisa que não se confere na nova versão.

    O cache miss ratio é dado pela divisão entre os acessos à cache e a quantidade de erros, sendo assim temos uma métrica em proporção e não em valores absolutos.

    \hspace*{-2.0cm}\includegraphics[width=16cm]{graphs/op1_gradient_L3}

    Aqui, podemos observar um uso muito melhor da comunicação entre processador e memória, visto que a largura de banda aumenta notavelmente na versão otimizada.
    Isso indica que mais dados são transmitidos por segundo, otimizando o acesso à memória.

    Tal melhoria ocorre porque, com o formato CSR, os dados utilizados ficam contíguos na memória, aumentando a localidade espacial e, consequentemente, a quantidade de dados trafegados

    \subsection{Cálculo do Resíduo}\label{subsec:residue}

    \hspace*{-2.0cm}\includegraphics[width=16cm]{graphs/op2_residue_Exec_Time}

    No gráfico acima percebemos uma melhora relativa entre a primeira versão (não otimizada) e a segunda (otimizada), que se mostra mais significativa em tamanhos de larga escala.
    
    Tais melhoras podem ser justificadas pelos gráficos a seguir, bem como pelo uso do modelo \textbf{CSR}.

    \hspace*{-2.0cm}\includegraphics[width=16cm]{graphs/op2_residue_Flops_Avx}
    
    No que diz respeito ao uso de Flops \textbf{AVX} no cálculo do resíduo temos que na nova versão otimizada não houve o uso da extensão em nenhum momento, coisa que após analisarmos o código do programa e as métricas, consideramos ser devido ao uso do \textbf{CSR},
    que acaba nos obrigando a fazer o acesso indireto de um vetor, isso impede o \textbf{AVX} de ser executado.

    Ademais, existe dependência de dados na variável \textit{sum}, outro impecilho ao \textbf{AVX}.

    \hspace*{-2.0cm}\includegraphics[width=16cm]{graphs/op2_residue_Flops_Dp}

    Ao contrário do que foi visto no último grafico, podemos perceber aqui uma impressiva melhora, ao passo que realiza muitos mais cálculos em uma mesma quantidade de tempo, acelerando o programa.

    O funcionamento e a explicação deste gráfico seguem igualmente à do \textbf{CG}.

    \clearpage

    \hspace*{-2.0cm}\includegraphics[width=16cm]{graphs/op2_residue_L2Cache}

    Neste ponto é possivel notar que não houve melhora no \textit{Miss Ratio} da cache \textbf{L2}, até mesmo representando uma pequena piora em parte dos casos.

    Essa maior \textit{taxa de miss} ocorre, principalmente, pelos acessos indiretos e distantes que o cálculo do resíduo acaba fazendo por conta do \textbf{CSR}\@.

    \clearpage

    \hspace*{-2.0cm}\includegraphics[width=16cm]{graphs/op2_residue_L3}

    A \textbf{bandwidth} da cache \textbf{L3} apresentou uma piora, pois menos dados estão sendo carregados por segundo, mesmo que a diferença seja, geralmente, pequena.
    Isso ocorre, de fato, devido à natureza dos acessos indiretos à memória e ao modo de funcionamento do formato \textbf{CSR}.
    No entanto, como mencionado anteriormente, essa piora é sobreposta pelo ganho nas outras operações e, mais ainda, compensada pelo tempo economizado nas iterações do \textbf{CG}.

    \subsection{Observações}\label{subsec:obs}

    É importante notar que, ainda que alguns gráficos mostrem um resíduo ligeiramente pior, o ganho obtido nas demais métricas de desempenho é mais significativo.
    Adicionalmente, o principal gargalo do programa encontra-se na iteração do \textbf{CG}.

    Portanto, é altamente vantajoso comprometer uma pequena porção do desempenho no cálculo do resíduo, visando a implementação de uma estrutura que otimize e acelere a iteração do gradiente.

    \clearpage

    \section{Resultados e Análise de Desempenho}\label{sec:resultados}

    Os resultados demonstram que a combinação do armazenamento \textbf{CSR} com a vetorização \textbf{AVX} produziu uma redução significativa no tempo de execução total,
    especialmente em sistemas de alta dimensão e esparsidade.

    A Tabela 1 resume o ganho de desempenho (speedup) alcançado para as operações críticas:

    \begin{table}[h]
        \centering
        \caption{Comparação de Tempo de Execução: Original vs. Otimizado (Tempo para N=20.000 em milisegundos)}
        \begin{tabular}{|c|c|c|c|}
            \hline
            \textbf{Operação} & \textbf{Tempo Original} & \textbf{Tempo Otimizado} & \textbf{Speedup} \\
            \hline
            Iteração do PCG & 23.60  & 0.0097 & 2432.98x \\
            \hline
            Cálculo do Resíduo & 0.87 & 0.17 & 5.11x \\
            \hline
        \end{tabular}\label{tab:table}
    \end{table}

    Vale ressaltar que no teste de N = 20.000 do 1º trabalho, o \textbf{LIKWID} não gerou nenhum dado correspondente a execução, portanto apenas a medida de tempo deve ser considerada, já que todas as outras 
    são iguais a zero.

    \clearpage

    \section{Estimativa de Desempenho}\label{sec:Estimativa de Desempenho}
    
    Baseado nas modificações implementadas na segunda versão e considerando uma máquina com 8GB de memória RAM disponível para seu programa e Sistemas com 7 (sete) diagonais, pode-se responder às perguntas
    dadas no enunciado do trabalho.

    \begin{enumerate}
        \item Qual o valor máximo estimado da ordem N do sistema linear que você seria capaz de resolver?
        \vspace{1ex}

        \textit{Após breves discussões, concluímos que conseguiriamos resolver até um sistema de ordem 12. Apesar de demanadar muito tempo e esforço, parece uma métrica realizável em algumas horas.}

        \item Qual o ganho estimado de tempo para uma iteração do método de Gradiente Conjugado com Pré-condicionador de Jacobi (em função de N)?

        \vspace{1ex}
        \textit{Estimamos que o ganho de desempenho seria algo dentre o intervalo de 8 a 16 vezes mais rápido. Pois, acreditavamos que isso já seria um ganho notável de desempenho.}

        \item Qual a estimativa para a quantidade de operações em ponto flutuante executadas em cada iteração do método de Gradiente Conjugado com Pré-condicionador de Jacobi (em função de N)?
        \vspace{1ex}

        \textit{Estimamos que teriamos em torno de 100 Flops Dp por segundo no método de Gradiente Conjulgado, coisa que já seria melhor que no primeiro trabalho.}

        \item Compare suas estimativas acima com os resultados obtidos nos testes.
       
        \vspace{1ex}
        \textit{Bom, apenas as perguntas '2.' e '3.' podem ser comparadas, visto que a primeira não trata sobre o programa/otimizações em si.}
        
        \textit{Sobre o ganho estimado (2.); percebemos que a diferença foi muito maior, chegando a casos da segunda versão apresentar um tempo de execução 2458 vezes menor que a versão 1.}
        
        \textit{Já sobre a quantidade de operações de ponto flutuante (3.); obtivemos 120 Flops Dp em média nos testes, bem como tivemos um expressivo aumento em Flops AVX.}
    \end{enumerate}



    \section{Conclusão}\label{sec:conclusao}

    Por fim, nota-se que as operações críticas do método dos Gradientes Conjugados foram otimizadas com sucesso.
    Utilizando métodos estruturais (como a matriz \textbf{CSR} para matrizes esparsas) e técnicas de paralelismo ao nível de instrução (como a \textbf{vetorização AVX}),
    alcançamos uma melhoria substancial no desempenho do programa.
    Conseguimos confirmar a execução otimizada pelo \textbf{AVX} em pelo menos uma das operações e, como resultado,
    \textbf{diminuímos drasticamente} o tempo de execução total do algoritmo, tornando o Método dos Gradientes Conjugados
    mais eficiente para a resolução de sistemas lineares de grande escala.

    \clearpage

    \nocite{*}
    \bibliography{references}
    \bibliographystyle{plain}

\end{document}
